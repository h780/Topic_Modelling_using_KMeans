# Topic_Modelling_using_KMeans
In this project we will use unsupervised technique - KMeans, to cluster/ group reviews to identify main topics/ ideas in the sea of text. This will be applicable to any textual reviews. In this series, we will focus on twitter data which is more real world and more complex data compared to reviews obtained from review or survey forms.

1. There is large amount of data present everywhere. If we see social media, or any other for of data, it is unstructured and needs to be properlly structured. So, this topic is becoming important every day. Also the storage capacity is increasing to make it available more readily and easily.

2. However, as we have lots of data hence more information is also associated with us. It becomes difficult to access what we're looking for. 

3. We need to organize, search, and understand this vast quantity of data.

4. Topic modelling helps in discovering the hidden topics/patterns in data.

5. It also helps in annotating the data so that it can be used in further identifying the data based on topics identified.

6. Topic modelling can also be defined as finding a group of words from the collection of documents that best represents the collection of information.

7. Topic modelling can also be thought as form of text mining as we're mining vast amount of textual infomation and way to obtain recurring patterns of words in the textual material.

8. In order to this we use unsupervised machine learning techniques, as we don't have labels for data.

9. This will help in clustering and grouping of the data, to identify the main topics and idea from the data.

This project works on data obtained from twitter. It is more complex and noisy when compared with data 
obtained from review forms of any other surveys.

NLTK: Natural Language Toolkit: It basically provides us with tool to enable the computer to understand natural language. It is a leading platform to build python programs to work with human language data. Human language data is very unstructu- red, that means same things can be said in multiple ways. 

For eg: I hope, you're doing well. 
        I hope, all is well.
        I hope, everything is fine with you.

All of the above 3 sentences are saying the same thing, but the words are attached differently when comparing these statements. Hence, for a computer they are different sentences which can mean different things.

So, NLTK helps computer understand human language data and helps with cleaning and re-processing the data to convert it into more structured form. It has text-processing libraries like classification, tokenization, stemming, stopwords removal, & tagging. It is free and open-sourced toolkit. We can directly import NLTK.
